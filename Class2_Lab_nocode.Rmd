---
title: "SMML Class 2 Lab"
author: "John Kubale"
date: "9/3/2024"
output:  pdf_document
number_sections: yes
fontsize: 12pt
---


```{r setup, include=FALSE, tidy=TRUE}
knitr::opts_chunk$set(echo = TRUE,cache=TRUE, 
                      autodep=TRUE, cache.comments=FALSE,
                      message=FALSE, warning=FALSE,
                      fig.width=4.5, fig.height=3.5)
```



##  We will use \texttt{Wage} data in R package \texttt{ISLR} <br>
```{r, echo=FALSE} 
library(ISLR2)
library(tidyverse)
```

```{r}
data("Wage") 
dim(Wage)
summary(Wage)
```
 
### 1. Focus on the variable, \texttt{wage}
A. Mean and variance of \texttt{wage}
```{r}
mean(Wage$wage)
var(Wage$wage)
```
Does the var() function give you the population or sample variance (hint: ?var)?
Sample!

B. Manually calculate the population and sample variance for wage. The code for calculating the population variance is provided. You will have to tweak it to calculate the sample variance.
```{r}
library(dplyr)

n <- dim(Wage)[[1]]


# calculate population variance
Wage%>%
  mutate(dif2 = (wage - mean(wage))^2,
         )%>%
  summarise(pop_var = (sum(dif2)/3000))

# calculate sample variance
Wage%>%
  mutate(dif2 = (wage - mean(wage))^2,
         )%>%
  summarise(sample_var = (sum(dif2)/(3000-1)))

```
Which matches what you got using var()? Which is larger and why do you think that is?
The sample variation, because normally we don't collect population data 

B. Using the sample variance of the estimated mean you've already calculated, estimate the 95% confidence interval of the true mean? 
```{r}

# calculate sample size of Wage and save sample variance of Wage$wage as object called "sampvar"
n <- dim(Wage)[[1]]
sampvar <- var(Wage$wage)
#sampvar*(n-1)/n

# calculate the appropriate t statistic to calculate a 95% CI for mean of wage
t.score<-qt(p=.05/2, df=n-1, lower.tail=F)
t.score

# calculate 95% CI for estimated mean of wage
lowCI <- mean(Wage$wage)-t.score*sqrt(sampvar)/sqrt(n)
upCI <- mean(Wage$wage)+t.score*sqrt(sampvar)/sqrt(n)
print(c(lowCI,upCI))

# Conduct single sample t-test of Wage$wage with 95% CI.
t.test(Wage$wage, conf.level = 0.95)
```
* How would you interpret the 95% confidence interval of the mean?
If we were to take repeated samples, the true mean of the population lies within the intervals 95% of the time 

* What are the null and alternative hypotheses associated with the t-test you ran above?
Null: True mean is equal to 0
ALternative: True mean is not equal to 0

* How does the 95% CI from t.test() compare to the interval you calculated by hand?\
They're equal 

C. Does \texttt{wage} follow a normal distribution? 
```{r, echo=FALSE}
library(ggplot2)
``` 

```{r, error=TRUE}
ggplot(Wage, aes(x=wage)) + geom_histogram(binwidth=5)
qqnorm(Wage$wage, main="Wage", ylab="y_{i:n}", xlab="m_{i:n}")+ 
qqline(Wage$wage, col="red",lwd=2)


```
* Based on the figures would you say wage is normally distributed?
No, it's right-skewed


```{r}
shapiro.test(Wage$wage)
```
* How would you interpret the results of the Shapiro-Wilk Normality test? \
Null: It is normally distributed
Alternative: THis is not normally distributed

D. What are the steps to take to compare \texttt{wage} of those without vs. with college or higher education? (Hints: What do you need to assess before using a two sample t-test?)
$H_0: \mu_{\ge CollEduc}=\mu_{<CollEduc}$ vs. $H_A: \mu_{\ge CollEduc} \neq \mu_{<CollEduc}$ 

  * Step 1) Recode \texttt{education}
  * Step 2) Check means and variances by recoded education
  * Step 3) ?
  * Step 4) Conduct proper testing
 
Step 1) Recode \texttt{education}
```{r}
# library(tidyverse) -- this will load dplyr and a number of other packages 
library(dplyr)
table(Wage$education)
Wage <- Wage%>%
  mutate(CollEduc=ifelse(education=="4. College Grad"|
                         education=="5. Advanced Degree",1,0))

```
* Look at the help page for the ifelse() function. What is the code above doing?

Step 2) Check means and variances by recoded education
```{r}
Wage%>%
  group_by(CollEduc)%>% #grouped by new binary variable
  summarize(m=mean(wage),
            var=var(wage))
```

* $\hat\mu_{<CollEduc}=\hat{\bar{y}}_{<CollEduc}=98.2$ and $\hat{\sigma}^2_{<CollEduc}=s^2_{<CollEduc}=910$
* $\hat\mu_{\ge CollEduc}=\hat{\bar{y}}_{\ge CollEduc}=135$ and $\hat{\sigma}^2_{\ge CollEduc}=s^2_{\ge CollEduc}=2324$ \

Step 3) Test equal variance
* Corresponding hypothesis: $H_0:\sigma^2_{<CollEduc}=\sigma^2_{\ge CollEduc}$ vs. $H_A:\sigma^2_{< CollEduc}\neq\sigma^2_{\ge CollEduc}$

```{r}
var.test(wage ~ CollEduc, Wage, alternative = "two.sided")
```
* What are the null and alternative hypotheses associated with the var.test() above?
* How do you interpret the results? \

Step 4) Conduct proper testing based on what you found in the previous step.
* Corresponding hypothesis: $H_0: \mu_{<CollEduc}=\mu_{\ge CollEduc}$ vs. $H_A: \mu_{<CollEduc} \neq \mu_{\ge CollEduc}$
```{r}


```
* What are the null/alternative hypotheses associated with this t-test?
* How do you interpret the results?
* How would you conduct this test if you came to the opposite conclusion (regarding the two sample variances) in the previous step?\

E. What is the correlation coefficient between \texttt{wage} and \texttt{age}? 
```{r}
cor(Wage$wage, Wage$age)
cor.test(Wage$wage, Wage$age)

```
\hfill

What are the conclusions from F? 
Can we use conclusions from above?

F. If we're concerned that the wage distribution in the groups we want to compare (here it is those with/without college education) we should consider using a non-parametric test for comparing means like the Wilcoxon test.
```{r}
# stratify by college education status and look at each distribution as before (i.e., histogram, qqplot, normality test)
coll_edu <- filter(Wage, CollEduc==1) ## Subset Wage data to only include those with college edu or greater
nocoll_edu <- filter(Wage, CollEduc!=1) ## Subset Wage data to only include those with less than college edu 
```

How could we  compare the two wage distributions since? Conduct a Wilcoxon rank sum (AKA Mann-Whitney U test) test comparing the mean wage of those without vs. with college or higher education.
```{r}
# conduct non-parametric test
wilcox.test(wage ~ CollEduc, data = Wage,
                    exact = FALSE, conf.int=0.95)
```
* How do the results compare to the t-test you conducted earlier? \

\newpage

### 2. Focus on the variable, \texttt{logwage}

A. What is the estimated mean and variance of the sample?
```{r}

```
\

B. What is the sample standard error for logwage? Use it to calculate 95% confidence interval of the true mean.
```{r}


```
* The sample standard error is $$.
* The 95% confidence interval of $\mu_{logwage}$ is $[, ]$\

C. Does \texttt{logwage} follow a normal distribution? Evaluate its distribution both graphically and statistically.
```{r, error=TRUE}

```

```{r}

```
* While, compared to \texttt{wage}, \texttt{logwage} appears more normally distributed, it still fails to meet the normal distribution requirements.\

D. Assess the relationship between \texttt{wage} and \texttt{logwage}.
```{r}
ggplot(Wage, aes(x=wage,y=logwage)) + geom_point()
```

* How would you describe the relationship between Wage and logwage?\

```{r}
# There are often multiple ways in R to achieve the same result.
mean(log(Wage$wage))
mean(Wage$logwage)
```

 


